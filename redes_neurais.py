# -*- coding: utf-8 -*-
"""Redes Neurais.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tVBUwtLDwaDPApalI9KY90KorEkyPqFx
"""



"""1. Pesquisa Teórica  
   a) Pesquise e explique o conceito de aprendizado supervisionado, comparando-o com outros tipos de aprendizado (não supervisionado e por reforço).  # Aprendizado Supervisionado

Em um ambiente de aprendizado supervisionado, o modelo se beneficia de dados rotulados, permitindo previsões precisas e confiáveis, essenciais para aplicações práticas. O aprendizado não supervisionado, por sua vez, opera com dados não rotulados, focando na exploração e na identificação de padrões ocultos. Já o aprendizado por reforço se destaca pela interação contínua com um ambiente, onde o agente aprende a tomar decisões com base em feedback recebido após as ações. Essa diferença é crucial: enquanto o aprendizado supervisionado recebe feedback durante o treinamento, permitindo um aprendizado direcionado, o aprendizado por reforço requer uma abordagem mais dinâmica, ajustando-se a partir de recompensas e penalidades. Assim, a escolha entre essas abordagens deve considerar os objetivos do projeto e a natureza dos dados disponíveis.
Supervisionado:
Algoritmos podem ser treinados em conjuntos de dados que incluem características de pacientes (como idade, histórico familiar e sintomas) e seus diagnósticos confirmados. Um estudo publicado na revista Nature demonstrou que algoritmos de aprendizado supervisionado podem igualar ou superar médicos humanos na detecção de câncer de pele.
Não supervisionado:
Técnicas como agrupamento (clustering) ajudam a identificar segmentos de clientes que podem ser alvos específicos para campanhas de marketing. Um exemplo prático é o uso de algoritmos de clustering para segmentar consumidores em base de dados de compras, permitindo personalização de ofertas.
Por reforço:
O jogo de Go, por exemplo, foi revolucionado pela IA AlphaGo, que utilizou aprendizado por reforço para se tornar um campeão mundial. Em robótica, o aprendizado por reforço é utilizado para ensinar robôs a executar tarefas complexas, como navegação em ambientes dinâmicos.

A seguir, abordarei o aprendizado supervisionado, não supervisionado e por reforço, destacando aspectos de funcionalidade, usabilidade, disponibilidade e eficiência.

Aprendizado Supervisionado
No aprendizado supervisionado, o modelo é treinado com um conjunto de dados rotulados. Essa abordagem permite que o sistema aprenda a mapear entradas (features) para saídas (labels) de forma precisa.

Funcionalidade: A funcionalidade é bem definida, pois os rótulos guiam o aprendizado do modelo. Isso resulta em previsões mais precisas e confiáveis, essenciais em aplicações como diagnósticos médicos e classificação de emails.

Usabilidade: A usabilidade é elevada, uma vez que o usuário pode entender facilmente as previsões do modelo com base em exemplos rotulados. Isso facilita a interpretação dos resultados.

Disponibilidade: A disponibilidade de dados rotulados é um fator crítico. Em muitos casos, pode ser desafiador obter um conjunto de dados suficientemente grande e representativo.

Eficiência: O treinamento de modelos supervisionados pode ser computacionalmente intensivo, mas a precisão alcançada frequentemente justifica o investimento em termos de recursos.

Aprendizado Não Supervisionado
Por outro lado, o aprendizado não supervisionado utiliza dados não rotulados, buscando identificar padrões e estruturas subjacentes.

Funcionalidade: A funcionalidade é mais exploratória. O modelo pode descobrir agrupamentos naturais nos dados, o que é útil para segmentação de mercado ou identificação de anomalias.

Usabilidade: A usabilidade pode ser mais desafiadora, já que os resultados não são diretamente interpretáveis sem rótulos. Isso pode dificultar a aplicação prática dos insights gerados.

Disponibilidade: Uma vantagem do aprendizado não supervisionado é a menor dependência de dados rotulados, o que facilita o uso em cenários onde a rotulagem é inviável.

Eficiência: A eficiência pode ser superior, pois o modelo pode ser treinado com dados em larga escala sem a necessidade de rótulos, economizando tempo e recursos.

Aprendizado por Reforço
O aprendizado por reforço, por sua vez, envolve um agente que aprende a tomar decisões em um ambiente dinâmico.

Funcionalidade: Essa abordagem é altamente funcional em cenários onde a tomada de decisão é crucial, como jogos ou sistemas autônomos. O agente pode aprender a maximizar recompensas com base em suas ações.

Usabilidade: A usabilidade depende da clareza das recompensas e penalidades definidas. Se mal projetadas, podem levar a comportamentos indesejados.

Disponibilidade: A necessidade de um ambiente dinâmico e interativo para o treinamento pode ser uma limitação, exigindo mais infraestrutura e planejamento.

Eficiência: O treinamento pode ser demorado, pois o agente precisa explorar e experimentar diversas ações antes de encontrar uma estratégia eficaz.

Referências
Esteva, A., Kuprel, B., Arawal, A., et al. (2017). A Deep Learning Algorithm Using Convolutional Neural Networks for the Detection of Melanoma from Skin Lesions. Nature.
Kaufman, L., & Rousseeuw, P. J. (1990). Finding Groups in Data: An Introduction to Cluster Analysis. Wiley-Interscience.
Silver, D., Huang, A., Maddison, C. J., et al. (2016). Mastering the Game of Go with Deep Neural Networks and Tree Search. Nature.

b) Descreva a estrutura básica de uma rede neural artificial, incluindo camadas de entrada, ocultas e de saída.  
 Estrutura Básica de uma Rede Neural Artificial

Camada de Entrada:

A camada de entrada é fundamental, pois é responsável por receber os dados iniciais. Cada neurônio nesta camada representa uma característica (feature) dos dados. Por exemplo, em uma rede neural que classifica imagens, cada neurônio pode corresponder a um pixel da imagem, permitindo que a rede processe informações visuais de forma detalhada.


Camadas Ocultas:

Entre a camada de entrada e a camada de saída, encontramos uma ou mais camadas ocultas, que são essenciais para o processamento das informações. Os neurônios dessas camadas realizam cálculos complexos utilizando pesos e funções de ativação, permitindo que a rede aprenda padrões e relações subjacentes nos dados. O número de camadas ocultas e neurônios pode variar conforme a complexidade do problema em questão. Redes mais profundas e com mais neurônios têm maior capacidade de capturar padrões complexos, embora isso também possa aumentar o risco de overfitting, onde a rede se ajusta excessivamente aos dados de treinamento.

Camada de Saída:

Finalmente, a camada de saída fornece a previsão final da rede. O número de neurônios nesta camada geralmente corresponde ao número de classes em um problema de classificação. Por exemplo, em um problema de classificação de dígitos, como o conjunto de dados MNIST, a camada de saída terá 10 neurônios, representando os dígitos de 0 a 9. A função de ativação utilizada na camada de saída pode ser softmax para problemas de classificação, convertendo as saídas em probabilidades, ou linear para problemas de regressão, dependendo da natureza do problema.


Camada de Entrada:

Função: A camada de entrada é a primeira interação da rede neural com os dados. Recebe as informações brutas diretamente do ambiente ou de um conjunto de dados estruturados. Cada neurônio nesta camada representa uma característica (feature) do conjunto de dados.
Características:
Formato de Dados: Pode lidar com diferentes tipos de dados, como imagens, texto, ou números, dependendo da aplicação.
Escalonamento: É comum aplicar técnicas de pré-processamento, como normalização ou padronização, para garantir que todas as características sejam representadas em uma escala semelhante, o que ajuda na convergência do modelo durante o treinamento.
Exemplo: Em um modelo que classifica imagens, cada neurônio pode representar um pixel, permitindo que a rede capture detalhes visuais desde o início, como cores, intensidades e bordas.
Camadas Ocultas:

Função: As camadas ocultas são responsáveis pelo processamento avançado dos dados. Elas realizam cálculos complexos que permitem à rede identificar padrões e extrações de características mais profundas. Cada neurônio nessa camada aplica uma função de ativação, que introduz não linearidades essenciais para a modelagem de dados complexos.
Características:
Profundidade da Rede: O número de camadas ocultas e neurônios em cada camada pode variar; redes mais profundas podem aprender representações hierárquicas dos dados, enquanto redes rasas podem ser insuficientes para capturar a complexidade necessária.
Regularização: Para mitigar o overfitting, técnicas como dropout, batch normalization e regularização L2 podem ser aplicadas, ajudando a rede a generalizar melhor em dados novos.
Exemplo: Em uma rede para reconhecimento de padrões, camadas ocultas podem detectar características básicas como bordas em camadas iniciais e, em camadas mais profundas, reconhecer formas complexas e objetos inteiros.

Camada de Saída:

Função: A camada de saída é responsável por fornecer a previsão final da rede. O número de neurônios nesta camada geralmente corresponde ao número de classes no problema que a rede está tentando resolver. Essa camada traduz as informações processadas em resultados interpretáveis.
Características:
Função de Ativação: A escolha da função de ativação na camada de saída é crítica; a função softmax é frequentemente utilizada para problemas de classificação múltipla, convertendo as saídas em probabilidades que somam 1, enquanto a função linear é usada em problemas de regressão, onde se busca prever valores contínuos.
Interpretabilidade: Os resultados desta camada são utilizados para tomar decisões, como classificar uma imagem ou prever um valor, tornando sua interpretação essencial para a eficácia da aplicação.
Exemplo: Em uma tarefa de classificação de dígitos, a camada de saída terá 10 neurônios, cada um representando um dígito de 0 a 9. A rede retorna a classe com a maior probabilidade como a previsão final.

Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer.

Este livro é um clássico na área de aprendizado de máquina e fornece uma base teórica sólida sobre redes neurais e outros algoritmos de aprendizado.
Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.

Um dos textos mais abrangentes sobre aprendizado profundo, que cobre a arquitetura de redes neurais, incluindo camadas de entrada, ocultas e de saída.
LeCun, Y., Bengio, Y., & Haffner, P. (1998). "Gradient-Based Learning Applied to Document Recognition." Proceedings of the IEEE, 86(11), 2278-2324.

Um artigo seminal que discute a aplicação de redes neurais para reconhecimento de padrões, incluindo a estrutura básica das redes.
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). "Learning Representations by Back-Propagating Errors." Nature, 323(6088), 533-536.

Este artigo introduz o algoritmo de retropropagação, fundamental para o treinamento de redes neurais.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.

Uma referência que cobre muitos aspectos do aprendizado de máquina, incluindo redes neurais, com uma boa explicação das camadas e funções de ativação.

2. Implementação Prática  
   a) Implemente uma rede neural artificial em Python utilizando bibliotecas como TensorFlow, Keras ou PyTorch.

Neste projeto, desenvolvemos uma rede neural artificial para a tarefa de classificação de padrões a partir de dados relacionados ao Bitcoin. O objetivo é explorar as capacidades das redes neurais em aprender padrões a partir de dados financeiros e avaliar o desempenho do modelo. Utilizando a biblioteca TensorFlow, implementamos uma arquitetura sequencial com camadas de entrada, ocultas e de saída, ajustando hiperparâmetros essenciais para otimizar a acurácia do modelo. A seguir, apresentamos a metodologia, os resultados obtidos e as discussões sobre possíveis melhorias.
"""

Código

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt

# Carregar e preparar os dados MNIST
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape((60000, 28 * 28)).astype('float32') / 255
x_test = x_test.reshape((10000, 28 * 28)).astype('float32') / 255

# Criar o modelo da rede neural
model = models.Sequential()
model.add(layers.Dense(128, activation='relu', input_shape=(28 * 28,)))
model.add(layers.Dropout(0.2))  # Adicionando Dropout
model.add(layers.BatchNormalization())  # Adicionando Batch Normalization
model.add(layers.Dense(10, activation='softmax'))

# Compilar o modelo
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Treinar o modelo
history = model.fit(x_train, y_train, epochs=10, validation_split=0.2)

# Avaliar o modelo
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f'Acurácia no teste: {test_acc}')

# Plotar a acurácia e a perda
plt.figure(figsize=(12, 4))

# Gráfico de Acurácia
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')
plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()
plt.title('Acurácia do Modelo')

# Gráfico de Perda
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perda de Treinamento', color='blue')
plt.plot(history.history['val_loss'], label='Perda de Validação', color='orange')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend()
plt.title('Perda do Modelo')

plt.tight_layout()
plt.show()

# Importar bibliotecas necessárias para a criação e treinamento da rede neural
# TensorFlow é uma das bibliotecas mais utilizadas para aprendizado de máquina e redes neurais,
# projetada para facilitar a criação de modelos complexos e seu treinamento em grande escala.
# Ela oferece uma vasta gama de
# funcionalidades e módulos que ajudam desenvolvedores e pesquisadores,
# incluindo:
# - `tf.data`: para manipulação eficiente de conjuntos de dados e pré-processamento.
# - `tf.optimizers`: que inclui otimizadores avançados como Adam, RMSProp, entre outros.
# - `tf.losses`: para uma variedade de funções de perda, adequadas a diferentes tarefas de aprendizado.
# - `tf.keras`: uma API de alto nível que permite construir e treinar modelos de aprendizado profundo de forma intuitiva.

#   Métodos comuns incluem:
#   - `Sequential()`: usado para criar um modelo sequencial, onde as camadas são empilhadas linearmente.

#   - `add()`: adiciona uma camada ao modelo.

#   - `compile()`: configura o modelo para o treinamento, especificando otimizadores e funções de perda.

# - `tf.data`: utilizado para manipulação e pré-processamento eficiente de conjuntos de dados.

#   - `Dataset.from_tensor_slices()`: permite criar um objeto de conjunto de dados a partir de tensores.

# - `tf.optimizers`: oferece uma variedade de algoritmos de otimização, como:

#   - `Adam`: um otimizador popular que ajusta automaticamente a taxa de aprendizado.

# - `tf.losses`: contém várias funções de perda, como:

#   - `sparse_categorical_crossentropy`: utilizada em tarefas de classificação quando as classes são representadas por inteiros.
# Com suporte a computação em GPU, TensorFlow permite o treinamento de modelos em larga escala, tornando-se a escolha preferida por muitos na indústria e na pesquisa.
import tensorflow as tf  # Biblioteca principal para aprendizado de máquina
from tensorflow.keras import layers, models  # Importa módulos para criar camadas e modelos de rede neural
from tensorflow.keras.datasets import mnist  # Importa o conjunto de dados MNIST para classificação de dígitos
import matplotlib.pyplot as plt  # Biblioteca para visualização de dados e criação de gráficos

# Carregar e preparar os dados MNIST, um conjunto de dados amplamente utilizado para treinar sistemas de aprendizado de máquina
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalizar os dados de entrada para facilitar o treinamento da rede neural
# Os valores dos pixels das imagens variam de 0 a 255; ao dividir por 255, transformamos esses valores em um intervalo de 0 a 1.
# Isso melhora a convergência do modelo, pois as funções de ativação funcionam melhor com dados normalizados.
x_train = x_train.reshape((60000, 28 * 28)).astype('float32') / 255  # Reestrutura os dados de entrada e normaliza
x_test = x_test.reshape((10000, 28 * 28)).astype('float32') / 255  # O mesmo processo é realizado para os dados de teste

# Criar o modelo da rede neural usando uma arquitetura sequencial, onde as camadas são empilhadas linearmente
model = models.Sequential()
# Adicionar a primeira camada oculta com 128 neurônios, utilizando a função de ativação ReLU (Rectified Linear Unit)
# Essa função é escolhida por sua eficiência em evitar o problema de gradientes desaparecendo, comum em redes profundas.
model.add(layers.Dense(128, activation='relu', input_shape=(28 * 28,)))  # Camada oculta com 128 neurônios
# Adicionar a camada de saída, que terá 10 neurônios correspondendo às classes de dígitos de 0 a 9.
# A função softmax é utilizada para calcular a probabilidade de cada classe, permitindo que a rede escolha a classe mais provável.
model.add(layers.Dense(10, activation='softmax'))  # Camada de saída para 10 classes de dígitos

# Compilar o modelo, especificando o otimizador, a função de perda e as métricas que queremos monitorar durante o treinamento
# O otimizador 'adam' é uma escolha popular por sua adaptabilidade e eficiência.
# A função de perda 'sparse_categorical_crossentropy' é adequada para problemas de classificação com múltiplas classes.
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Treinar o modelo com os dados de treinamento. Aqui, estamos usando 20% dos dados para validação, o que permite monitorar
# a performance do modelo em dados que não foram utilizados para treinamento, ajudando a evitar overfitting.
history = model.fit(x_train, y_train, epochs=5, validation_split=0.2)  # Treinamento com 20% dos dados para validação

# Avaliar o modelo com o conjunto de dados de teste para verificar sua performance em dados não vistos
# Essa etapa é fundamental para entender a capacidade do modelo de generalizar para novos dados.
test_loss, test_acc = model.evaluate(x_test, y_test)  # Avaliação nos dados de teste
print(f'Acuracia no teste: {test_acc}')  # Exibir a acurácia do modelo nos dados de teste, indicando seu desempenho

# Plotar a acurácia ao longo das épocas para visualizar o desempenho do modelo durante o treinamento
# O gráfico nos ajudará a entender se o modelo está aprendendo adequadamente e se há sinais de overfitting.
plt.plot(history.history['accuracy'], label='Acuracia de Treinamento')  # Acurácia durante o treinamento
plt.plot(history.history['val_accuracy'], label='Acuracia de Validacao')  # Acurácia durante a validação
plt.xlabel('Epocas')  # Rótulo do eixo X representando o número de épocas de treinamento
plt.ylabel('Acuracia')  # Rótulo do eixo Y representando a acurácia do modelo
plt.legend()  # Adicionar legenda para distinguir as linhas no gráfico
plt.title('Acuracia do Modelo')  # Título do gráfico que indica que ele mostra a acurácia do modelo ao longo das épocas
plt.show()  # Exibir o gráfico resultante da acurácia ao longo das épocas
# Gráfico de Perda
plt.subplot(1, 2, 2)  # 1 linha, 2 colunas, 2ª posição
plt.plot(history.history['loss'], label='Perda de Treinamento', color='blue')  # Perda durante o treinamento
plt.plot(history.history['val_loss'], label='Perda de Validacao', color='orange')  # Perda durante a validação
plt.xlabel('Epocas')  # Rótulo do eixo X representando o número de épocas de treinamento
plt.ylabel('Perda')  # Rótulo do eixo Y representando a perda do modelo
plt.legend()  # Adicionar legenda para distinguir as linhas no gráfico
plt.title('Perda do Modelo')  # Título do gráfico que indica que ele mostra a perda do modelo ao longo das épocas# Ajusta o layout e exibe os gráficos
plt.tight_layout()
plt.show()  # Exibir os gráficos resultantes da acurácia e perda ao longo das épocas

"""**Escolha de Hiperparâmetros**

*Número de Neurônios*

Justificativa: O número de neurônios em uma camada oculta deve ser escolhido com base na complexidade do problema. Para tarefas como a classificação de dígitos (MNIST), um valor comum é entre 128 e 512. Um número muito baixo pode resultar em subajuste (underfitting), enquanto um número muito alto pode levar ao sobreajuste (overfitting).

*Épocas de Treinamento*

Justificativa: A escolha do número de épocas depende da convergência do modelo. Um valor comum para MNIST é entre 5 e 20 épocas. Monitorar a perda de validação ajuda a evitar o overfitting, permitindo o uso de early stopping.

**Escolha do Otimizador e da Função de Perda**

*Otimizador*

Escolha: O otimizador Adam é uma escolha popular devido à sua adaptabilidade e eficiência em grandes conjuntos de dados. Ele combina as vantagens de dois outros extensões de otimização, oferecendo um bom compromisso entre velocidade e precisão.

*Função de Perda*

Escolha: A função de perda sparse_categorical_crossentropy é apropriada para problemas de classificação com múltiplas classes. Ela calcula a perda de forma eficiente quando as classes são representadas por inteiros.

Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.

Um livro fundamental que cobre teoria de aprendizado de máquina e redes neurais.
Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.

Uma referência abrangente sobre aprendizado profundo, incluindo arquiteturas de redes neurais.
LeCun, Y., Bengio, Y., & Haffner, P. (1998). "Gradient-Based Learning Applied to Document Recognition". Proceedings of the IEEE.

Um artigo clássico que discute a aplicação de redes neurais na classificação de dígitos.

b) Utilize a rede neural para resolver um problema de classificação supervisionada. Sugestão: classificar imagens (ex.: MNIST Dataset) ou prever categorias de textos (ex.: análise de sentimentos). Link do Catalogo para escolha do dataset
"""

# Montar o Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Importar bibliotecas necessárias
import pandas as pd  # Para manipulação de dados

# Carregar o arquivo CSV
data = pd.read_csv('/content/drive/My Drive/Colab/btcusd_1-min_data.csv')

# Exibir as primeiras linhas do dataset
print(data.head())

# Importar bibliotecas necessárias
import pandas as pd  # Para manipulacao de dados
import tensorflow as tf  # Biblioteca principal para aprendizado de maquina
from tensorflow.keras import layers, models  # Importa modulos para criar camadas e modelos de rede neural
from sklearn.model_selection import train_test_split  # Para dividir os dados em treinamento e teste
import matplotlib.pyplot as plt  # Biblioteca para visualizacao de dados e criacao de graficos

# Carregar os dados
data = pd.read_csv('/content/drive/MyDrive/Colab/btcusd_1-min_data.csv')  # Ajuste o caminho do arquivo

# Exibir as primeiras linhas do dataset
print(data.head())  # Verificar as primeiras linhas do dataset

# Verificar os nomes das colunas
print(data.columns)  # Exibir os nomes das colunas

# Preparar os dados
# Usando a coluna 'Close' como rotulo
X = data.drop(['Timestamp', 'Close'], axis=1).values[:10000]  # Limitar a 10.000 amostras
y = data['Close'].values[:10000]  # Limitar a 10.000 amostras
X = X.astype('float32') / X.max()  # Normalizacao dos dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Dividir os dados

# Criar o modelo
model = models.Sequential()  # Criar um modelo sequencial
model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))  # Camada oculta com menos neuronios
model.add(layers.Dropout(0.5))  # Adicionar regularizacao com Dropout
model.add(layers.Dense(1))  # Camada de saida ajustada para prever um valor continuo

# Compilar o modelo
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Usar erro medio quadratico para regressao

# Treinar o modelo
history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)  # Alterar para 5 epochs

# Avaliar o modelo
test_loss, test_mae = model.evaluate(X_test, y_test)  # Avaliar nos dados de teste
print(f'MAE no teste: {test_mae}')  # Exibir o MAE do modelo

# Visualizar resultados
plt.plot(history.history['mae'], label='MAE de Treinamento')  # MAE durante o treinamento
plt.plot(history.history['val_mae'], label='MAE de Validacao')  # MAE durante a validacao
plt.xlabel('Epocas')  # Rotulo do eixo X
plt.ylabel('MAE')  # Rotulo do eixo Y
plt.legend()  # Adicionar legenda
plt.title('MAE do Modelo')  # Titulo do grafico
plt.show()  # Exibir o grafico

"""Definir a Tarefa de Classificação: Vamos criar uma nova coluna que indique se o preço de fechamento subiu ou desceu em relação ao preço de abertura.
Alterar a Estrutura do Modelo
"""

# Importar bibliotecas necessárias
import pandas as pd  # Para manipulacao de dados
import tensorflow as tf  # Biblioteca principal para aprendizado de maquina
from tensorflow.keras import layers, models  # Importa modulos para criar camadas e modelos de rede neural
from sklearn.model_selection import train_test_split  # Para dividir os dados em treinamento e teste
import matplotlib.pyplot as plt  # Biblioteca para visualizacao de dados e criacao de graficos

# Carregar os dados
data = pd.read_csv('/content/drive/MyDrive/Colab/btcusd_1-min_data.csv')  # Ajuste o caminho do arquivo

# Exibir as primeiras linhas do dataset
print(data.head())  # Verificar as primeiras linhas do dataset

# Verificar os nomes das colunas
print(data.columns)  # Exibir os nomes das colunas

# Criar a coluna de classe (1 para alta, 0 para baixa)
data['Price_Change'] = (data['Close'] > data['Open']).astype(int)

# Preparar os dados
X = data.drop(['Timestamp', 'Close', 'Open', 'Price_Change'], axis=1).values[:10000]  # Limitar a 10.000 amostras
y = data['Price_Change'].values[:10000]  # Limitar a 10.000 amostras
X = X.astype('float32') / X.max()  # Normalizacao dos dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Dividir os dados

# Criar o modelo
model = models.Sequential()  # Criar um modelo sequencial
model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))  # Camada oculta com menos neuronios
model.add(layers.Dropout(0.5))  # Adicionar regularizacao com Dropout
model.add(layers.Dense(1, activation='sigmoid'))  # Camada de saida com ativacao sigmoid para classificacao binaria

# Compilar o modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Usar binary crossentropy para classificacao binaria

# Treinar o modelo
history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)  # Alterar para 5 epochs

# Avaliar o modelo
test_loss, test_accuracy = model.evaluate(X_test, y_test)  # Avaliar nos dados de teste
print(f'Acuracia no teste: {test_accuracy}')  # Exibir a acuracia do modelo

# Visualizar resultados
plt.plot(history.history['accuracy'], label='Acuracia de Treinamento')  # Acuracia durante o treinamento
plt.plot(history.history['val_accuracy'], label='Acuracia de Validacao')  # Acuracia durante a validacao
plt.xlabel('Epocas')  # Rotulo do eixo X
plt.ylabel('Acuracia')  # Rotulo do eixo Y
plt.legend()  # Adicionar legenda
plt.title('Acuracia do Modelo')  # Titulo do grafico
plt.show()  # Exibir o grafico

""""Dados Históricos do Bitcoin
Neste projeto, analisamos dados históricos do Bitcoin em intervalos de 1 minuto, abrangendo o período de janeiro de 2012 até o presente. Utilizamos arquivos CSV que contêm informações de trocas selecionadas, incluindo dados OHLC (Abertura, Alto, Baixo, Fechamento) e o volume em BTC, medidos por dia em UTC.

É importante ressaltar que, caso um carimbo de data e hora esteja faltando ou se houver saltos nos dados, isso pode ocorrer devido à inatividade da troca ou da sua API, à inexistência da troca, ou a erros técnicos imprevistos durante a coleta ou relatório dos dados. Embora tenhamos feito o possível para desduplicar entradas e garantir que o conteúdo esteja correto e completo, recomendamos cautela na interpretação dos dados.

Agradecimentos e Inspiração
Gostaria de expressar minha gratidão à API Bitstamp, que forneceu dados essenciais para este projeto. A busca por APIs de troca que disponibilizassem dados de OHLC e volume em intervalos de 1 minuto foi desafiadora, mas gratificante. Além disso, sou grato a Satoshi Nakamoto, cuja visão sobre o blockchain e a primeira execução através do protocolo Bitcoin inspiram continuamente a inovação neste campo. Agradeço também aos leitores e espectadores, e estou ansioso para ver quais códigos ou insights vocês têm a compartilhar." Fonte Kangle url https://www.kaggle.com/datasets/mczielinski/bitcoin-historical-data

3. Aprimoramento do Modelo  
   a) Faça experimentos com a rede neural, variando parâmetros como:
   - Número de camadas ocultas.
   - Número de neurônios por camada.
   - Funções de ativação (sigmóide, ReLU, softmax).
   - Taxa de aprendizado.
"""

import pandas as pd  # Para manipulacao de dados
import tensorflow as tf  # Biblioteca principal para aprendizado de maquina
from tensorflow.keras import layers, models  # Importa modulos para criar camadas e modelos de rede neural
from sklearn.model_selection import train_test_split  # Para dividir os dados em treinamento e teste
import matplotlib.pyplot as plt  # Biblioteca para visualizacao de dados e criacao de graficos

# Carregar os dados
data = pd.read_csv('/content/drive/MyDrive/Colab/btcusd_1-min_data.csv')

# Criar a coluna de classe
data['Price_Change'] = (data['Close'] > data['Open']).astype(int)

# Preparar os dados
X = data.drop(['Timestamp', 'Close', 'Open', 'Price_Change'], axis=1).values[:10000]  # Limitar a 10.000 amostras
y = data['Price_Change'].values[:10000]  # Limitar a 10.000 amostras
X = X.astype('float32') / X.max()  # Normalizacao dos dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Dividir os dados

# Criar o modelo com variacoes
model = models.Sequential()  # Criar um modelo sequencial
model.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)))  # Camada oculta 1
model.add(layers.Dense(64, activation='sigmoid'))  # Camada oculta 2
model.add(layers.Dense(32, activation='softmax'))  # Camada oculta 3
model.add(layers.Dense(1, activation='sigmoid'))  # Camada de saida

# Compilar o modelo com taxa de aprendizado ajustada
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Taxa de aprendizado
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # Usar binary crossentropy para classificacao binaria

# Treinar o modelo
history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)  # Alterar para 10 epochs

# Avaliar o modelo
test_loss, test_accuracy = model.evaluate(X_test, y_test)  # Avaliar nos dados de teste
print(f'Acuracia no teste: {test_accuracy}')  # Exibir a acuracia do modelo

# Visualizar resultados
plt.plot(history.history['accuracy'], label='Acuracia de Treinamento')  # Acuracia durante o treinamento
plt.plot(history.history['val_accuracy'], label='Acuracia de Validacao')  # Acuracia durante a validacao
plt.xlabel('Epocas')  # Rotulo do eixo X
plt.ylabel('Acuracia')  # Rotulo do eixo Y
plt.legend()  # Adicionar legenda
plt.title('Acuracia do Modelo')  # Titulo do grafico
plt.show()  # Exibir o grafico

"""Alteração Adicional de ativação"""

import pandas as pd  # Para manipulacao de dados
import tensorflow as tf  # Biblioteca principal para aprendizado de maquina
from tensorflow.keras import layers, models  # Importa modulos para criar camadas e modelos de rede neural
from sklearn.model_selection import train_test_split  # Para dividir os dados em treinamento e teste
import matplotlib.pyplot as plt  # Biblioteca para visualizacao de dados e criacao de graficos

# Carregar os dados
data = pd.read_csv('/content/drive/MyDrive/Colab/btcusd_1-min_data.csv')

# Criar a coluna de classe
data['Price_Change'] = (data['Close'] > data['Open']).astype(int)

# Preparar os dados
X = data.drop(['Timestamp', 'Close', 'Open', 'Price_Change'], axis=1).values[:10000]  # Limitar a 10.000 amostras
y = data['Price_Change'].values[:10000]  # Limitar a 10.000 amostras
X = X.astype('float32') / X.max()  # Normalizacao dos dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Dividir os dados

# Criar o modelo
model = models.Sequential()  # Criar um modelo sequencial
model.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)))  # Camada oculta 1
model.add(layers.Dense(64, activation='relu'))  # Camada oculta 2
model.add(layers.Dense(32, activation='sigmoid'))  # Camada oculta 3
model.add(layers.Dense(1, activation='sigmoid'))  # Camada de saida

# Compilar o modelo com uma taxa de aprendizado ajustada
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Taxa de aprendizado
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])  # Usar binary crossentropy para classificacao binaria

# Treinar o modelo
history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)  # Alterar para 10 epochs

# Avaliar o modelo
test_loss, test_accuracy = model.evaluate(X_test, y_test)  # Avaliar nos dados de teste
print(f'Acuracia no teste: {test_accuracy}')  # Exibir a acuracia do modelo

# Visualizar resultados
plt.plot(history.history['accuracy'], label='Acuracia de Treinamento')  # Acuracia durante o treinamento
plt.plot(history.history['val_accuracy'], label='Acuracia de Validacao')  # Acuracia durante a validacao
plt.xlabel('Epocas')  # Rotulo do eixo X
plt.ylabel('Acuracia')  # Rotulo do eixo Y
plt.legend()  # Adicionar legenda
plt.title('Acuracia do Modelo')  # Titulo do grafico
plt.show()  # Exibir o grafico

"""b) Apresente os efeitos dessas mudanças no desempenho da rede, utilizando métricas como acurácia, precisão e recall."""

plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')
plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')
plt.title('Acurácia do Modelo')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()
plt.show()

"""Para avaliar os efeitos dessas mudanças, utilizamos métricas como acurácia, precisão e recall. A acurácia é a proporção de previsões corretas entre o total de previsões. A precisão indica a proporção de verdadeiros positivos entre todos os positivos previstos, enquanto o recall mostra a proporção de verdadeiros positivos entre todos os positivos reais."""

# Visualizar resultados de acurácia
plt.plot(history.history['accuracy'], label='Acuracia de Treinamento')
plt.plot(history.history['val_accuracy'], label='Acuracia de Validacao')
plt.title('Acuracia do Modelo')
plt.xlabel('Epocas')
plt.ylabel('Acuracia')
plt.legend()
plt.show()

# Para calcular precisão e recall, podemos usar o sklearn
from sklearn.metrics import classification_report

y_pred = (model.predict(X_test) > 0.5).astype(int)  # Previsões binárias
print(classification_report(y_test, y_pred))

"""Calcular e exibir acurácia, precisão e recall"""

from sklearn.metrics import classification_report, confusion_matrix

# Fazer previsões no conjunto de teste
y_pred = (model.predict(X_test) > 0.5).astype(int)

# Exibir o relatório de classificação
print(classification_report(y_test, y_pred))

# Exibir a matriz de confusão
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusão:")
print(conf_matrix)

"""**Métricas Adicionais**"""

# Importar bibliotecas necessarias
import pandas as pd  # Para manipulacao de dados
import tensorflow as tf  # Biblioteca principal para aprendizado de maquina
from tensorflow.keras import layers, models  # Importa modulos para criar camadas e modelos de rede neural
from sklearn.model_selection import train_test_split  # Para dividir os dados em treinamento e teste
from imblearn.over_sampling import SMOTE  # Para balancear os dados
from sklearn.metrics import classification_report, roc_curve, auc  # Para metricas de avaliacao
import matplotlib.pyplot as plt  # Biblioteca para visualizacao de dados e criacao de graficos
from collections import Counter  # Para contar as classes

# Carregar os dados
data = pd.read_csv('/content/drive/MyDrive/Colab/btcusd_1-min_data.csv')  # Ajuste o caminho do arquivo

# Criar a coluna de classe (1 para alta, 0 para baixa)
data['Price_Change'] = (data['Close'] > data['Open']).astype(int)

# Preparar os dados
X = data.drop(['Timestamp', 'Close', 'Open', 'Price_Change'], axis=1).values[:10000]  # Limitar a 10.000 amostras
y = data['Price_Change'].values[:10000]  # Limitar a 10.000 amostras
X = X.astype('float32') / X.max()  # Normalizacao dos dados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Dividir os dados

# Balancear os dados usando SMOTE
print("Distribuicao das classes antes do SMOTE:", Counter(y_train))  # Exibir distribuicao das classes

# Ajustar o número de vizinhos (n_neighbors)
k_neighbors = min(5, len(y_train[y_train == 1]) - 1)  # Use um valor que não exceda o número de amostras da classe 1

smote = SMOTE(random_state=42, k_neighbors=k_neighbors)  # Inicializar SMOTE com o k ajustado
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)  # Aplicar SMOTE

print("Distribuicao das classes apos o SMOTE:", Counter(y_resampled))  # Exibir distribuicao das classes

# Criar o modelo com mais camadas e neuronios
model = models.Sequential()  # Criar um modelo sequencial
model.add(layers.Dense(128, activation='relu', input_shape=(X_resampled.shape[1],)))  # Camada oculta com 128 neuronios
model.add(layers.Dense(64, activation='relu'))  # Adicionando uma segunda camada oculta
model.add(layers.Dropout(0.5))  # Adicionar regularizacao com Dropout
model.add(layers.Dense(1, activation='sigmoid'))  # Camada de saida com ativacao sigmoid para classificacao binaria

# Compilar o modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Usar binary crossentropy para classificacao binaria

# Habilitar TensorBoard
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)

# Treinar o modelo com os dados balanceados
history = model.fit(X_resampled, y_resampled, epochs=5, batch_size=64, validation_split=0.2, callbacks=[tensorboard_callback])  # Alterar para 5 epochs

# Avaliar o modelo
test_loss, test_accuracy = model.evaluate(X_test, y_test)  # Avaliar nos dados de teste
print(f'Acuracia no teste: {test_accuracy}')  # Exibir a acuracia do modelo

# Visualizar resultados de acuracia
plt.plot(history.history['accuracy'], label='Acuracia de Treinamento')  # Acuracia durante o treinamento
plt.plot(history.history['val_accuracy'], label='Acuracia de Validacao')  # Acuracia durante a validacao
plt.title('Acuracia do Modelo')  # Titulo do grafico
plt.xlabel('Epocas')  # Rotulo do eixo X
plt.ylabel('Acuracia')  # Rotulo do eixo Y
plt.legend()  # Adicionar legenda
plt.show()  # Exibir o grafico

# Calcular e exibir as metricas de classificacao
y_pred = (model.predict(X_test) > 0.5).astype(int)  # Previsoes binarias
print(classification_report(y_test, y_pred))  # Relatorio de classificacao

# Adicionar a curva ROC
y_probs = model.predict(X_test).ravel()  # Prever as probabilidades
fpr, tpr, thresholds = roc_curve(y_test, y_probs)  # Calcular a curva ROC
roc_auc = auc(fpr, tpr)  # Calcular a area sob a curva

# Plotar a curva ROC
plt.figure()
plt.plot(fpr, tpr, color='blue', label='Curva ROC (area = %0.2f)' % roc_auc)  # Plotar a curva
plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Linha de referencia
plt.xlim([0.0, 1.0])  # Limitar eixo X
plt.ylim([0.0, 1.05])  # Limitar eixo Y
plt.xlabel('Taxa de Falsos Positivos')  # Rotulo do eixo X
plt.ylabel('Taxa de Verdadeiros Positivos')  # Rotulo do eixo Y
plt.title('Curva ROC')  # Titulo do grafico
plt.legend(loc='lower right')  # Posicao da legenda
plt.show()  # Exibir o grafico

"""Após o treinamento, executar o seguinte comando para iniciar o TensorBoard:

"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir ./logs

"""4. Documentação e Análise  
   a) Documente detalhadamente o processo de implementação da rede neural, incluindo os principais desafios enfrentados e as decisões tomadas.

**Documentação e Análise**
Carregamento e Pré-processamento dos Dados
No início do nosso projeto, decidimos utilizar o conjunto de dados MNIST, conhecido por conter imagens de dígitos escritos à mão. O carregamento deste dataset foi facilitado pela biblioteca Keras, que nos permitiu acessar as imagens de forma rápida e eficiente. Durante o pré-processamento, normalizamos os valores das imagens para o intervalo de 0 a 1. Essa normalização é fundamental, pois facilita o treinamento da rede neural, permitindo que os pesos sejam atualizados de maneira mais eficaz.

Além disso, remodelamos as imagens para incluir um canal, o que é uma exigência para as camadas convolucionais que usaríamos posteriormente. Essa etapa garantiu que nossas imagens estivessem no formato correto para a aplicação das operações de convolução.

Construção do Modelo
A construção do modelo foi um momento empolgante. Inicialmente, optamos por uma arquitetura simples, composta por duas camadas convolucionais seguidas de camadas de pooling. Essa estrutura é amplamente utilizada, pois permite a extração de características relevantes das imagens, reduzindo a dimensionalidade e mantendo a informação essencial.

Para as camadas ocultas, escolhemos a função de ativação 'ReLU'. Essa escolha se baseou em sua comprovada eficácia em redes profundas, contribuindo para um aprendizado mais rápido e eficiente. Na camada de saída, utilizamos 'softmax', que é ideal para problemas de classificação múltipla, pois nos fornece as probabilidades de cada classe.

Compilação e Treinamento do Modelo
Na fase de compilação, optamos pelo otimizador Adam, conhecido por sua adaptabilidade e desempenho em diferentes cenários. Para a função de perda, utilizamos 'sparse_categorical_crossentropy', que se adequa perfeitamente ao nosso problema de classificação.

O treinamento foi realizado inicialmente por 5 épocas. Após essa fase, fizemos um ajuste na arquitetura do modelo, adicionando mais camadas e neurônios. Com essa nova configuração, realizamos um treinamento adicional por 10 épocas, buscando uma melhora significativa na performance do modelo.

Desafios Enfrentados
Um dos principais desafios que enfrentamos foi o ajuste do número de camadas e neurônios. Realizamos uma série de testes com diferentes configurações, o que demandou um tempo considerável. Esse processo de experimentação foi essencial para encontrar a melhor arquitetura.

Além disso, a monitorização do overfitting se tornou um ponto crucial durante o treinamento. À medida que aumentávamos a complexidade da rede, era vital observar se o modelo estava realmente aprendendo a generalizar ou apenas memorizando os dados de treinamento. Implementamos técnicas de validação e regularização para garantir que nosso modelo mantivesse uma boa capacidade de generalização.

Avaliação do Modelo
Finalmente, após o treinamento, avaliamos a acurácia do modelo utilizando o conjunto de teste. Esse foi um momento de validação do nosso trabalho. Com calma e tranquilidade, revisamos os resultados, observando que a performance do modelo atendia nossas expectativas, refletindo o esforço e as decisões estratégicas tomadas ao longo do processo.

**Detalhes **
Dados Reais: Se os dados utilizados são reais e representativos, os resultados tendem a ser mais fiéis. No entanto, se os dados forem sintéticos ou manipulados, os resultados podem não refletir a realidade.

Configuração do Modelo: A escolha de hiperparâmetros (número de camadas, neurônios, funções de ativação, taxa de aprendizado, etc.) influencia diretamente a performance do modelo. Resultados podem ser simbólicos se a configuração não estiver otimizada para os dados.

Amostragem e Balanceamento: Em problemas de classificação desbalanceada, como o que você mencionou (classe 0 e classe 1), a performance pode parecer boa (alta acurácia) mesmo que o modelo tenha dificuldades em prever a classe minoritária. Portanto, é essencial analisar as métricas de precisão e recall, não apenas a acurácia.

Avaliação de Desempenho: Resultados como precisão e recall fornecem uma visão mais clara da performance do modelo. Se esses valores para a classe minoritária forem baixos, pode indicar que os resultados são mais simbólicos do que fiéis.

b) Inclua gráficos e tabelas que ilustrem a evolução do erro durante o treinamento e a performance final do modelo.
"""

import matplotlib.pyplot as plt

# Visualizando a evolução da perda e acurácia
plt.figure(figsize=(12, 5))

# Gráfico de Acurácia
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')
plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')
plt.title('Evolução da Acurácia')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()

# Gráfico de Perda
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perda de Treinamento')
plt.plot(history.history['val_loss'], label='Perda de Validação')
plt.title('Evolução da Perda')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend()

plt.tight_layout()
plt.show()

"""Gráfico de Acurácia: A curva de acurácia de treinamento e validação geralmente mostra um aumento contínuo ao longo das épocas, indicando que o modelo está aprendendo. A acurácia de validação deve se aproximar da de treinamento, indicando boa generalização.

Gráfico de Perda: A perda de treinamento deve diminuir ao longo do tempo. Se a perda de validação começar a aumentar enquanto a perda de treinamento continua a diminuir, isso pode indicar overfitting.

Tabela de Resultados Finais: A tabela resume as principais métricas do modelo após o treinamento. A alta acurácia sugere que o modelo é capaz de classificar a maioria das imagens corretamente.

Analise
"""

import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import classification_report

# Evolucao do Erro Durante o Treinamento e Performance Final do Modelo
# Neste bloco, vamos visualizar a acurácia e a perda do modelo ao longo das épocas de treinamento.
# Esses gráficos ajudam a entender como o modelo se comporta e se está aprendendo de maneira eficiente.
# Além disso, vamos gerar um relatório de métricas de desempenho, incluindo precisão, recall e F1-score.

# Gráfico de Acurácia
plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Acuracia de Treinamento')  # Acurácia de treinamento
plt.plot(history.history['val_accuracy'], label='Acuracia de Validacao')  # Acurácia de validação
plt.title('Evolucao da Acuracia do Modelo')  # Título do gráfico
plt.xlabel('Epocas')  # Rótulo do eixo x
plt.ylabel('Acuracia')  # Rótulo do eixo y
plt.legend()  # Legenda para identificar as linhas
plt.grid()  # Adiciona uma grade ao gráfico
plt.show()  # Exibe o gráfico

# Gráfico de Perda
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Perda de Treinamento')  # Perda de treinamento
plt.plot(history.history['val_loss'], label='Perda de Validacao')  # Perda de validação
plt.title('Evolucao da Perda do Modelo')  # Título do gráfico
plt.xlabel('Epocas')  # Rótulo do eixo x
plt.ylabel('Perda')  # Rótulo do eixo y
plt.legend()  # Legenda para identificar as linhas
plt.grid()  # Adiciona uma grade ao gráfico
plt.show()  # Exibe o gráfico

# Tabela de Performance Final do Modelo
# Aqui, calculamos e apresentamos as métricas de desempenho do modelo para cada classe.
# Isso nos permite avaliar a eficácia do modelo de forma mais detalhada.
y_pred = model.predict(X_test)  # Gerar previsões
y_pred_classes = (y_pred > 0.5).astype(int)  # Convertendo previsões para classes binárias

# Relatório de classificacao
report = classification_report(y_test, y_pred_classes, output_dict=True)  # Gerar relatório
report_df = pd.DataFrame(report).transpose()  # Transforma o relatório em um DataFrame

# Exibindo a tabela
print(report_df)  # Exibe a tabela com as métricas de desempenho

"""c) Discuta os resultados, abordando:
   - O desempenho da rede neural em relação a outros algoritmos.
   - A eficácia do aprendizado supervisionado no problema abordado.
   - Sugestões de melhorias para futuras implementações.

Desempenho da Rede Neural em Relação a Outros Algoritmos
O desempenho da rede neural foi notavelmente bom, apresentando uma acurácia de aproximadamente 99.85%. No entanto, ao analisarmos as métricas de precisão e recall, percebemos que, embora a classe 0 tenha sido identificada quase perfeitamente, a classe 1 apresentou uma precisão de apenas 40% com um recall de 100%. Isso indica que, enquanto o modelo consegue reconhecer todos os exemplos da classe 1, ele falha em fazer previsões corretas para a maioria dos casos, resultando em um desempenho desigual entre as classes.

Em comparação com outros algoritmos, como máquinas de vetor de suporte (SVM) ou árvores de decisão, as redes neurais geralmente se destacam em tarefas complexas, especialmente em reconhecimento de padrões e classificação de imagens. Entretanto, em conjuntos de dados desbalanceados, como o utilizado neste estudo, técnicas como Random Forest ou XGBoost podem oferecer um desempenho mais equilibrado, dado que lidam melhor com classes minoritárias.

Eficácia do Aprendizado Supervisionado no Problema Abordado
O aprendizado supervisionado demonstrou ser uma abordagem eficaz para o problema de classificação em questão. O modelo foi capaz de aprender padrões relevantes nos dados e, mesmo com a desvantagem do desbalanceamento das classes, conseguiu identificar a classe majoritária com alta precisão. Isso é um testemunho da capacidade do aprendizado supervisionado em extrair informações significativas a partir de dados rotulados, o que é fundamental em tarefas de classificação.

Contudo, a eficácia do modelo foi comprometida pela dificuldade em generalizar para a classe minoritária. Este ponto ressalta a importância de se considerar o balanceamento de dados como parte fundamental do processo de modelagem.

O aprendizado supervisionado demonstrou ser extremamente eficaz para o problema de classificação de dígitos manuscritos. A alta qualidade e a quantidade de dados rotulados disponíveis no MNIST possibilitam que o modelo aprenda padrões robustos. Este contexto é ideal para técnicas de aprendizado supervisionado, onde:

Dados Rotulados: A presença de rótulos claros para cada imagem permite que o modelo seja treinado de forma precisa.
Diversidade: O MNIST contém uma variedade de estilos de escrita, o que ajuda o modelo a generalizar melhor.
A combinação de uma rede neural bem projetada e um dataset de alta qualidade resultou em um modelo que não só tem alta acurácia, mas também é capaz de lidar com variações nos dados de entrada.

Sugestões de Melhorias para Futuras Implementações
Embora os resultados tenham sido positivos, sempre há espaço para melhorias. Algumas sugestões incluem:

Regularização: Implementar técnicas como dropout ou L2 regularization para prevenir overfitting, especialmente ao aumentar a complexidade da rede.
Aumento de Dados: Usar técnicas de data augmentation, como rotações, translações e mudanças de escala nas imagens, pode melhorar a robustez do modelo e sua capacidade de generalização.
Ajuste de Hiperparâmetros: Realizar uma busca sistemática (como Grid Search ou Random Search) para encontrar os melhores hiperparâmetros (taxa de aprendizado, número de camadas, número de neurônios, etc.) pode otimizar ainda mais o desempenho do modelo.
Exploração de Arquiteturas Avançadas: Testar modelos mais complexos, como ResNets ou DenseNets, que podem oferecer melhorias significativas em tarefas de classificação de imagens.
Transfer Learning: Utilizar modelos pré-treinados em datasets maiores pode acelerar o treinamento e melhorar o desempenho em tarefas específicas, mesmo com dados limitados.

**Sugestões de Melhorias para Futuras Implementações**
Uso de Métodos de Regularização:

A implementação de técnicas de regularização, como Dropout ou L2 Regularization, pode ajudar a mitigar o overfitting. Isso é especialmente importante em cenários com conjuntos de dados desbalanceados, onde a complexidade do modelo pode levar a uma generalização insuficiente.
Balanceamento de Dados:

Como o desbalanceamento entre as classes impactou a performance da rede, técnicas de balanceamento, como SMOTE (Synthetic Minority Over-sampling Technique) ou undersampling da classe majoritária, devem ser exploradas. Isso pode resultar em uma representação mais equitativa das classes e, consequentemente, em um aumento na precisão e recall da classe minoritária.
Utilização de Conjuntos de Dados Aumentados:

Para modelos de aprendizado profundo, aumentar o conjunto de dados pode ser uma solução eficaz. Técnicas de data augmentation podem ser aplicadas, gerando variações nas amostras de dados existentes. Isso não só ajuda a melhorar a robustez do modelo, mas também pode reduzir o risco de overfitting.
Avaliação de Outras Arquiteturas:

Explorar diferentes arquiteturas de rede, como Redes Neurais Convolucionais (CNNs) ou Redes Neurais Recorrentes (RNNs), dependendo da natureza dos dados, pode revelar melhores desempenhos em tarefas específicas, como a classificação de sequências temporais.
Monitoramento e Validação Contínua:

Implementar um sistema de monitoramento contínuo para avaliar o desempenho do modelo em produção. Isso pode incluir a utilização de métricas de desempenho em tempo real e a implementação de um processo de feedback, onde as previsões são constantemente validadas e refinadas.
Integração de Modelos Ensembling:

A técnica de ensemble, que combina múltiplos modelos para melhorar a precisão das previsões, pode ser considerada. Modelos como Random Forests ou Gradient Boosting podem ser utilizados em conjunto com a rede neural para fornecer um resultado mais robusto.
Exploração de Métricas Adicionais:

Para uma avaliação mais completa do modelo, incluir métricas como a curva ROC e a área sob a curva (AUC) pode oferecer uma visão mais detalhada sobre a capacidade do modelo de discriminar entre as classes, especialmente em cenários de desbalanceamento.

5- Relatório Final  
   Entregue um relatório contendo:
   - A pesquisa teórica.
   - O código-fonte da implementação.
   - Análise detalhada dos resultados, incluindo gráficos comparativos.
   - Reflexões sobre o impacto das alterações de parâmetros e possíveis melhorias.

Iniciamos com a pesquisa teórica, que é fundamental para entender o contexto da aplicação da rede neural. O aprendizado de máquina, em especial as redes neurais, é uma área que tem crescido significativamente, impulsionada pela disponibilidade de grandes volumes de dados e pelo aumento do poder computacional. As redes neurais são modelos inspirados no funcionamento do cérebro humano, compostas por camadas de neurônios que se comunicam entre si. Elas são particularmente eficazes em tarefas como classificação, regressão e reconhecimento de padrões. Neste projeto, utilizamos o conjunto de dados BTC/USD, que contém informações de transações de Bitcoin, com o objetivo de prever o preço de fechamento com base em características de mercado como abertura, alta, baixa e volume. Essa escolha é estratégica, considerando o crescimento e a volatilidade do mercado de criptomoedas.

Em seguida, apresentamos o código-fonte da implementação, que foi cuidadosamente elaborado para criar uma rede neural capaz de realizar previsões sobre o preço do Bitcoin. O código inclui a importação das bibliotecas essenciais, como TensorFlow e Pandas, que facilitam a manipulação dos dados e a construção do modelo. Após carregar e pré-processar os dados, dividimos o conjunto em dados de treinamento e teste. A estrutura da rede neural é simples, consistindo em uma camada densa com 128 neurônios e ativação ReLU, seguida por uma camada de saída que prevê um único valor contínuo. O modelo foi compilado com o otimizador Adam e uma função de perda apropriada para problemas de regressão. O treinamento foi realizado por 10 épocas, com validação para monitorar a performance do modelo.

Ao analisarmos os resultados, observamos que o modelo conseguiu atingir uma média de erro absoluto (MAE) relativamente baixa no conjunto de teste. As curvas de aprendizado, representadas em gráficos, mostram uma tendência positiva no desempenho ao longo das épocas, indicando que o modelo está aprendendo a partir dos dados. Os gráficos de MAE de treinamento e validação são particularmente ilustrativos, pois demonstram como o modelo se adapta ao conjunto de dados e como a validação ajuda a evitar overfitting.

Refletindo sobre o impacto das alterações de parâmetros, como o número de neurônios e as épocas de treinamento, notamos que uma configuração mais complexa pode, inicialmente, melhorar a capacidade de aprendizado, mas também aumenta o risco de overfitting. Um equilíbrio entre complexidade e generalização é essencial para o sucesso do modelo. Além disso, a normalização dos dados foi uma decisão crucial, pois assegura que as entradas da rede neural estejam na mesma escala, facilitando a convergência durante o treinamento.

Para futuras implementações, sugiro algumas melhorias. A inclusão de técnicas de regularização, como dropout, pode ser considerada para mitigar o overfitting. Além disso, explorar diferentes arquiteturas de rede e ajustar hiperparâmetros como a taxa de aprendizado podem resultar em um modelo mais robusto. A utilização de dados adicionais ou de maior qualidade também pode impactar positivamente a performance do modelo, permitindo previsões mais precisas.

Concluímos que a implementação de redes neurais para prever preços de ativos financeiros, como o Bitcoin, é uma tarefa desafiadora, mas que oferece um potencial significativo para análises de mercado. Através da combinação de pesquisa teórica sólida, implementação prática e uma análise cuidadosa dos resultados, conseguimos obter um modelo que não apenas se ajusta aos dados, mas que também abre portas para futuras investigações e melhorias. Assim, seguimos em frente, com a confiança de que cada passo dado nos aproxima mais de soluções inovadoras e eficientes.

Código-Fonte da Implementação
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# Carregar o dataset MNIST
mnist = keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalizar os dados
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# Remodelar os dados
x_train = x_train.reshape((60000, 28, 28, 1))
x_test = x_test.reshape((10000, 28, 28, 1))

# Construir a rede neural inicial
model = keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compilar o modelo
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Treinar o modelo
history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))

# Alterando número de camadas ocultas, neurônios e funções de ativação
model = keras.Sequential([
    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),  # Aumento de neurônios
    layers.Dense(10, activation='softmax')
])

# Compilar e treinar novamente
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

# Avaliar o modelo
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f'Acurácia do teste: {test_acc}')

# Visualizar a evolução da acurácia e perda
plt.figure(figsize=(12, 5))

# Gráfico de Acurácia
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')
plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')
plt.title('Evolução da Acurácia')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()

# Gráfico de Perda
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perda de Treinamento')
plt.plot(history.history['val_loss'], label='Perda de Validação')
plt.title('Evolução da Perda')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend()

plt.tight_layout()
plt.show()

"""Análise Detalhada dos Resultados
Gráficos Comparativos
Os gráficos mostraram a evolução da acurácia e perda durante o treinamento.

Gráfico de Acurácia: A acurácia de treinamento aumentou constantemente, alcançando cerca de 98,3% ao final do treinamento.
Gráfico de Perda: A perda de treinamento diminuiu, indicando que o modelo estava aprendendo.
"""

import matplotlib.pyplot as plt

# Visualizando a evolução da perda e acurácia
plt.figure(figsize=(12, 5))

# Gráfico de Acurácia
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')
plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')
plt.title('Evolução da Acurácia')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()

# Gráfico de Perda
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perda de Treinamento')
plt.plot(history.history['val_loss'], label='Perda de Validação')
plt.title('Evolução da Perda')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend()

plt.tight_layout()
plt.show()

"""O que os Gráficos Mostram
Gráfico de Acurácia:

Mostra como a acurácia do modelo evolui durante o treinamento e validação.
A expectativa é que a acurácia de treinamento aumente e a de validação se aproxime dela.
Gráfico de Perda:

Demonstra a perda do modelo ao longo do treinamento.
A perda deve diminuir conforme o modelo aprende, tanto nos dados de treinamento quanto nos de validação.
Instruções para Executar
Certifique-se de que o modelo já tenha sido treinado antes de executar o código dos gráficos.
Execute o código em um ambiente como Jupyter Notebook, Google Colab ou qualquer IDE Python que suporte visualizações.
Gráficos Comparativos
Os gráficos mostraram a evolução da acurácia e perda durante o treinamento.

Gráfico de Acurácia: A acurácia de treinamento aumentou constantemente, alcançando cerca de 98,3% ao final do treinamento.
Gráfico de Perda: A perda de treinamento diminuiu, indicando que o modelo estava aprendendo.

Reflexões sobre o Impacto das Alterações de Parâmetros e Possíveis Melhorias

Impacto das Alterações de Parâmetros
As alterações feitas nas camadas ocultas e no número de neurônios impactaram significativamente a performance do modelo. A adição de mais neurônios e camadas permitiu ao modelo aprender representações mais complexas dos dados, resultando em maior acurácia.

Possíveis Melhorias
Regularização: Implementar técnicas como dropout para prevenir overfitting.
Data Augmentation: Criar variações das imagens de treinamento para aumentar a robustez do modelo.
Ajuste de Hiperparâmetros: Realizar busca sistemática para otimizar hiperparâmetros.
Transfer Learning: Utilizar modelos pré-treinados para melhorar o desempenho em tarefas específicas.

Código Fonte
"""

# Montar o Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Importar bibliotecas necessárias
import pandas as pd  # Para manipulação de dados

# Carregar o arquivo CSV
data = pd.read_csv('/content/drive/My Drive/Colab/btcusd_1-min_data.csv')

# Exibir as primeiras linhas do dataset
print(data.head())

# Importar bibliotecas necessárias
import pandas as pd  # Para manipulacao de dados
import tensorflow as tf  # Biblioteca principal para aprendizado de maquina
from tensorflow.keras import layers, models  # Importa modulos para criar camadas e modelos de rede neural
from sklearn.model_selection import train_test_split  # Para dividir os dados em treinamento e teste
import matplotlib.pyplot as plt  # Biblioteca para visualizacao de dados e criacao de graficos

# Função para carregar os dados
def carregar_dados(caminho):
    try:
        data = pd.read_csv(caminho)  # Carregar o dataset
        print("Dados carregados com sucesso.")
        return data
    except Exception as e:
        print(f"Erro ao carregar os dados: {e}")
        return None

# Função para preparar os dados
def preparar_dados(data):
    X = data.drop(['Timestamp', 'Close'], axis=1).values[:10000]  # Limitar a 10.000 amostras
    y = data['Close'].values[:10000]  # Limitar a 10.000 amostras
    X = X.astype('float32') / X.max()  # Normalizacao dos dados
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Dividir os dados
    return X_train, X_test, y_train, y_test

# Função para criar o modelo
def criar_modelo():
    model = models.Sequential()  # Criar um modelo sequencial
    model.add(layers.Dense(128, activation='relu', input_shape=(None,)))  # Camada oculta com 128 neuronios
    model.add(layers.Dropout(0.5))  # Adicionar regularizacao com Dropout
    model.add(layers.Dense(1))  # Camada de saida ajustada para prever um valor continuo
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Compilar o modelo
    return model

# Função para treinar o modelo
def treinar_modelo(model, X_train, y_train):
    history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)  # Treinar o modelo
    return history

# Função para avaliar o modelo
def avaliar_modelo(model, X_test, y_test):
    test_loss, test_mae = model.evaluate(X_test, y_test)  # Avaliar nos dados de teste
    print(f'MAE no teste: {test_mae}')  # Exibir o MAE do modelo

# Função para visualizar resultados
def visualizar_resultados(history):
    plt.plot(history.history['mae'], label='MAE de Treinamento')  # MAE durante o treinamento
    plt.plot(history.history['val_mae'], label='MAE de Validação')  # MAE durante a validação
    plt.xlabel('Epocas')  # Rotulo do eixo X
    plt.ylabel('MAE')  # Rotulo do eixo Y
    plt.legend()  # Adicionar legenda
    plt.title('MAE do Modelo')  # Titulo do grafico
    plt.show()  # Exibir o grafico

# Execucao do fluxo principal
caminho = '/content/drive/MyDrive/Colab/btcusd_1-min_data.csv'  # Ajuste o caminho do arquivo para o BTC/USD
data = carregar_dados(caminho)  # Carregar os dados

if data is not None:
    X_train, X_test, y_train, y_test = preparar_dados(data)  # Preparar os dados
    model = criar_modelo()  # Criar o modelo
    history = treinar_modelo(model, X_train, y_train)  # Treinar o modelo
    avaliar_modelo(model, X_test, y_test)  # Avaliar o modelo
    visualizar_resultados(history)  # Visualizar resultados